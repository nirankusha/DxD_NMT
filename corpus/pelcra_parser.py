# -*- coding: utf-8 -*-
"""pelcra_parser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EbKM8NmBOCYKD_U0d6M3sdaCA2W5ZPHW
"""

#!/usr/bin/env python3
"""
PELCRACompleteParser
- Builds per-document TXT files (one per <text> per language: pl/en)
- Prepends bibliographic titles to each document
- Emits file_metadata.csv with rich fields for later DB patching

Usage:
  python pelcra_parser.py --xml /path/to/text_structure.xml --out /path/to/exports
"""

import argparse
import csv
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from lxml import etree

XML_NS  = "http://www.w3.org/XML/1998/namespace"
TEI_NS  = "http://www.tei-c.org/ns/1.0"
NS = {"xml": XML_NS, "tei": TEI_NS}

XML_PARSER = etree.XMLParser(
    recover=True,
    resolve_entities=False,
    huge_tree=True,
)

class PELCRACompleteParser:
    def __init__(self, xml_file: Path, out_root: Path):
        self.xml_file = Path(xml_file)
        self.out_root = Path(out_root)
        self.tree: Optional[etree._ElementTree] = None

    # ---------------- Public API ----------------
    def run(self) -> Tuple[Path, Path]:
        """Parse XML, write TXT + metadata CSV. Returns (export_root, metadata_csv)."""
        if not self.xml_file.exists():
            raise FileNotFoundError(f"XML not found: {self.xml_file}")

        self.out_root.mkdir(parents=True, exist_ok=True)

        # Parse and (optionally) resolve XInclude
        self.tree = etree.parse(str(self.xml_file), parser=XML_PARSER)
        try:
            self.tree.xinclude()
        except Exception:
            pass

        bibl_map = self._collect_bibl_map()
        docs, titles = self._collect_documents(bibl_map)

        if not docs:
            total_div_ns  = len(self.tree.xpath('//tei:div[@type="alignment_unit" and @subtype="sentence"]', namespaces=NS))
            total_div_raw = len(self.tree.xpath('//div[@type="alignment_unit" and @subtype="sentence"]'))
            raise RuntimeError(
                "No documents were collected.\n"
                f"- With TEI namespace: found {total_div_ns} sentence units\n"
                f"- Without namespace:  found {total_div_raw}\n"
                "If both are 0, check the file contains alignment units. "
                "If the non-NS count > 0, your file likely lacks TEI default namespace; "
                "the parser will already try a non-NS fallback, but verify structure."
            )

        meta_csv = self._write_outputs(docs, titles, bibl_map)
        print(f"✅ Export complete: {self.out_root}")
        print(f"   • Metadata CSV:  {meta_csv}")
        return self.out_root, meta_csv

    # ---------------- Internals ----------------
    def _collect_bibl_map(self) -> Dict[str, Dict[str, Optional[str]]]:
        """Build text_id → bibliographic metadata map. Namespace-aware with fallback."""
        assert self.tree is not None

        def first_txt(el, xpath: str, ns=None) -> Optional[str]:
            hits = el.xpath(xpath, namespaces=ns) if ns else el.xpath(xpath)
            if not hits:
                return None
            v = hits[0]
            if isinstance(v, str):
                return v.strip()
            return v.text.strip() if (getattr(v, "text", None)) else None

        out: Dict[str, Dict[str, Optional[str]]] = {}

        # First try namespace-aware TEI
        bibls = self.tree.xpath('//tei:bibl[@xml:id]', namespaces=NS)
        use_ns = True
        if not bibls:
            # Fallback: no-namespace
            bibls = self.tree.xpath('//bibl[@xml:id]')
            use_ns = False

        for bibl in bibls:
            ptr = bibl.xpath('./tei:ptr[@target]', namespaces=NS)[0] if use_ns else bibl.xpath('./ptr[@target]')[0]
            if ptr is None:
                continue
            target = ptr.get('target', '')
            if not target.startswith('#'):
                continue
            text_id = target[1:]

            if use_ns:
                meta = {
                    "bibl_id": bibl.get(f'{{{XML_NS}}}id'),
                    "pl_title_a": first_txt(bibl, './/tei:relatedItem[@xml:lang="pl"]//tei:title[@level="a"]', NS),
                    "pl_title_j": first_txt(bibl, './/tei:relatedItem[@xml:lang="pl"]//tei:title[@level="j"]', NS),
                    "en_title_a": first_txt(bibl, './/tei:relatedItem[@xml:lang="en"]//tei:title[@level="a"]', NS),
                    "en_title_j": first_txt(bibl, './/tei:relatedItem[@xml:lang="en"]//tei:title[@level="j"]', NS),
                    "author_pl":  first_txt(bibl, './/tei:relatedItem[@xml:lang="pl"]//tei:author', NS),
                    "author_en":  first_txt(bibl, './/tei:relatedItem[@xml:lang="en"]//tei:author', NS),
                    "date_published": first_txt(bibl, './/tei:date[@type="published"]', NS),
                    "url_pl": first_txt(bibl, './/tei:relatedItem[@xml:lang="pl"]//tei:ref[@type="display"]/@target', NS),
                    "url_en": first_txt(bibl, './/tei:relatedItem[@xml:lang="en"]//tei:ref[@type="display"]/@target', NS),
                }
            else:
                meta = {
                    "bibl_id": bibl.get(f'{{{XML_NS}}}id'),
                    "pl_title_a": first_txt(bibl, './/relatedItem[@xml:lang="pl"]//title[@level="a"]'),
                    "pl_title_j": first_txt(bibl, './/relatedItem[@xml:lang="pl"]//title[@level="j"]'),
                    "en_title_a": first_txt(bibl, './/relatedItem[@xml:lang="en"]//title[@level="a"]'),
                    "en_title_j": first_txt(bibl, './/relatedItem[@xml:lang="en"]//title[@level="j"]'),
                    "author_pl":  first_txt(bibl, './/relatedItem[@xml:lang="pl"]//author'),
                    "author_en":  first_txt(bibl, './/relatedItem[@xml:lang="en"]//author'),
                    "date_published": first_txt(bibl, './/date[@type="published"]'),
                    "url_pl": first_txt(bibl, './/relatedItem[@xml:lang="pl"]//ref[@type="display"]/@target'),
                    "url_en": first_txt(bibl, './/relatedItem[@xml:lang="en"]//ref[@type="display"]/@target'),
                }
            out[text_id] = meta
        return out

    def _collect_documents(
        self,
        bibl_map: Dict[str, Dict[str, Optional[str]]]
    ) -> Tuple[Dict[Tuple[str, str], List[str]], Dict[Tuple[str, str], str]]:
        """Collect sentences per (text_id, lang) and titles per (text_id, lang)."""
        assert self.tree is not None

        docs: Dict[Tuple[str, str], List[str]] = {}
        titles: Dict[Tuple[str, str], str] = {}

        # seed titles from bibl map
        for text_id, meta in bibl_map.items():
            pl = [meta.get('pl_title_a'), meta.get('pl_title_j')]
            en = [meta.get('en_title_a'), meta.get('en_title_j')]
            pl_header = "\n".join([t for t in pl if t]) if any(pl) else None
            en_header = "\n".join([t for t in en if t]) if any(en) else None
            if pl_header:
                titles[(text_id, 'pl')] = pl_header
            if en_header:
                titles[(text_id, 'en')] = en_header

        # 1) Namespace-aware path
        units = self.tree.xpath('//tei:div[@type="alignment_unit" and @subtype="sentence"]', namespaces=NS)
        use_ns = True
        if not units:
            # 2) Fallback: no namespace
            units = self.tree.xpath('//div[@type="alignment_unit" and @subtype="sentence"]')
            use_ns = False

        for unit in units:
            # find owning <text xml:id="...">
            cur = unit
            text_el = None
            while cur is not None:
                tag_local = cur.tag.split('}')[-1]
                if tag_local == 'text' and cur.get(f'{{{XML_NS}}}id'):
                    text_el = cur
                    break
                cur = cur.getparent()
            if text_el is None:
                continue

            text_id = text_el.get(f'{{{XML_NS}}}id')
            lang = self._get_lang(unit)
            if lang not in ('pl', 'en'):
                continue

            ab = unit.find('.//tei:ab', namespaces=NS) if use_ns else unit.find('.//ab')
            sent = (ab.text or '').strip() if ab is not None else ''
            if not sent:
                continue

            docs.setdefault((text_id, lang), []).append(sent)

        return docs, titles

    def _get_lang(self, elem) -> Optional[str]:
        cur = elem
        while cur is not None:
            lang = cur.get(f'{{{XML_NS}}}lang')
            if lang:
                return lang
            t = cur.get('type')
            if t == 'original':
                return 'pl'
            if t == 'translation':
                return 'en'
            cur = cur.getparent()
        return None

    def _write_outputs(
        self,
        docs: Dict[Tuple[str, str], List[str]],
        titles: Dict[Tuple[str, str], str],
        bibl_map: Dict[str, Dict[str, Optional[str]]]
    ) -> Path:
        pl_dir = self.out_root / "pl"
        en_dir = self.out_root / "en"
        pl_dir.mkdir(parents=True, exist_ok=True)
        en_dir.mkdir(parents=True, exist_ok=True)

        meta_rows: List[Dict[str, Optional[str]]] = []

        for (text_id, lang), sents in docs.items():
            header = titles.get((text_id, lang))
            parts = [header] if header else []
            parts.extend(sents)
            txt = "\n".join(parts).strip()

            out_path = (pl_dir if lang == "pl" else en_dir) / f"{text_id}.txt"
            out_path.write_text(txt, encoding="utf-8")

            bm = bibl_map.get(text_id, {})
            meta_rows.append({
                "text_id": text_id,
                "lang": lang,
                "filepath": str(out_path),
                "bibl_id": bm.get("bibl_id"),
                "title_a": bm.get("pl_title_a") if lang == "pl" else bm.get("en_title_a"),
                "title_j": bm.get("pl_title_j") if lang == "pl" else bm.get("en_title_j"),
                "author":  bm.get("author_pl") if lang == "pl" else bm.get("author_en"),
                "date_published": bm.get("date_published"),
                "url": bm.get("url_pl") if lang == "pl" else bm.get("url_en"),
            })

        meta_csv = self.out_root / "file_metadata.csv"
        if meta_rows:
            with meta_csv.open("w", newline="", encoding="utf-8") as f:
                w = csv.DictWriter(f, fieldnames=list(meta_rows[0].keys()))
                w.writeheader()
                w.writerows(meta_rows)
        else:
            raise RuntimeError("No metadata rows written — unexpected; check inputs.")

        return meta_csv


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--xml", required=True, help="Path to OSW TEI XML (text_structure.xml)")
    ap.add_argument("--out", required=True, help="Export root directory")
    args = ap.parse_args()

    parser = PELCRACompleteParser(Path(args.xml), Path(args.out))
    parser.run()

if __name__ == "__main__":
    main()